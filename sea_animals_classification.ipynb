{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🐠🦀🐙Classifying Sea 🌊 Animals 🐬🐳🦑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "from typing import Dict, List,Tuple\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from pathlib import Path, PurePath\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import datasets, models\n",
    "from torchvision import transforms\n",
    "import torch.optim as otim\n",
    "import torch.nn as nn\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# import albumentations as A\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# from imutils import paths\n",
    "\n",
    "# import splitfolders\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Structure\n",
    "\n",
    "This notebook template is for data that is already in ImageFolder format.\n",
    "\n",
    "If you are unfamiliar with ImageFolder format, it looks like this:\n",
    "\n",
    "```\n",
    "├── train\n",
    "│   ├── class1\n",
    "|      ├── 1.jpg\n",
    "│      ├── 2.jpg\n",
    "│   ├── class2\n",
    "|      ├── 1.jpg\n",
    "│      ├── 2.jpg\n",
    "├── valid\n",
    "│   ├── class1\n",
    "|      ├── 1.jpg\n",
    "│      ├── 2.jpg\n",
    "│   ├── class2\n",
    "|      ├── 1.jpg\n",
    "│      ├── 2.jpg\n",
    "```\n",
    "\n",
    "With parent folder repeating for validtaion and testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of classes\n",
    "\n",
    "Simple utility to fetch the number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subdirectories in Data/Sea Animals: 23\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_dir = 'Data/Sea Animals'\n",
    "\n",
    "def count_subdirectories(path: str) -> int:\n",
    "    \"\"\"\n",
    "    Counts the number of subdirectories in the given directory path.\n",
    "    \"\"\"\n",
    "    dir_path = Path(path)\n",
    "    subdirectories = [f for f in dir_path.iterdir() if f.is_dir()]\n",
    "    return len(subdirectories)\n",
    "\n",
    "# Example usage\n",
    "num_subdirectories = count_subdirectories(data_dir)\n",
    "print(f\"Number of subdirectories in {data_dir}: {num_subdirectories}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize the images to 224x224 pixels\n",
    "    transforms.ToTensor(),          # Convert images to PyTorch tensors\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset using ImageFolder\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train, validation, and test split ratios\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "# Calculate the sizes of each dataset split\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(train_ratio * dataset_size)\n",
    "val_size = int(val_ratio * dataset_size)\n",
    "test_size = dataset_size - train_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders for each split\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 9597\n",
      "Validation dataset size: 2056\n",
      "Test dataset size: 2058\n"
     ]
    }
   ],
   "source": [
    "# Check the sizes of each DataLoader\n",
    "print(f'Train dataset size: {len(train_loader.dataset)}')\n",
    "print(f'Validation dataset size: {len(val_loader.dataset)}')\n",
    "print(f'Test dataset size: {len(test_loader.dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example: Iterate through the train_loader\n",
    "for images, labels in train_loader:\n",
    "    print(images.size(), labels.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marc/miniconda3/envs/classification/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/marc/miniconda3/envs/classification/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/marc/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "3.1%"
     ]
    }
   ],
   "source": [
    "num_classes = len(dataset.classes)  # Number of classes in your dataset\n",
    "model = models.resnet18(pretrained=True)  # Load pre-trained ResNet18\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)  # Modify the final layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    # Step 5: Validate the model\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * images.size(0)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
